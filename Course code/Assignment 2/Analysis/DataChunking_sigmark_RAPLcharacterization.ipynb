{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47d806b8-69f3-4816-ad6c-af146c60faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import csv, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "797fc957-e425-45dc-83f5-294f3367d8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is F6D7-DE80\n",
      "\n",
      " Directory of c:\\Users\\eray2\\Documents\\Github\\semester3\\Energy-Consumption-2025\\Course code\\Assignment 2\\RawData\n",
      "\n",
      "01-11-2025  18:51    <DIR>          .\n",
      "01-11-2025  18:35    <DIR>          ..\n",
      "01-11-2025  18:51    <DIR>          Test\n",
      "               0 File(s)              0 bytes\n",
      "               3 Dir(s)  2.100.630.556.672 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls ..\\RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c0c07d3-8d71-4c2d-bc4a-4b1fc576a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = '..\\\\RawData'\n",
    "output_directory = '..\\\\ChunkedData\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b62cc016-128a-4268-90f2-feaff84c3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(input_directory)\n",
    "onlydir = [f for f in os.listdir(input_directory) if os.path.isdir(os.path.join(input_directory, f))]\n",
    "onlyfiles = [f for f in os.listdir(input_directory) if os.path.isfile(os.path.join(input_directory, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9c6a8d3-1442-44b6-a3e3-29fa1a0bde8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a0e5343-d1d1-4eb3-bc21-1877f39ea62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_line(line: str):\n",
    "    # csv.reader handles the quoted JSON payload with doubled quotes\n",
    "    return next(csv.reader([line], delimiter=',', quotechar='\"', doublequote=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd60b745-ebbe-4ff6-a078-26bfce646b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_json(perhaps_json):\n",
    "  try:\n",
    "    json.loads(perhaps_json)\n",
    "  except ValueError as e:\n",
    "    return False\n",
    "  return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f643c8fd-d0d4-405e-ad27-0097533936e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'start', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "{'action': 'stop', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "meta_row= {'computerID': 'DK1081104', 'class': 'cpu', 'start_time': 1761131594049, 'channelId': 'CH1', 'exp_duration': 20327}\n",
      "{'action': 'start', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "{'action': 'stop', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "meta_row= {'computerID': 'DK1081104', 'class': 'cpu', 'start_time': 1761131619395, 'channelId': 'CH1', 'exp_duration': 20377}\n",
      "{'action': 'start', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "{'action': 'stop', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "meta_row= {'computerID': 'DK1081104', 'class': 'cpu', 'start_time': 1761131644790, 'channelId': 'CH1', 'exp_duration': 20250}\n",
      "{'action': 'start', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "{'action': 'stop', 'computerID': 'DK1081104', 'class': 'cpu'}\n",
      "meta_row= {'computerID': 'DK1081104', 'class': 'cpu', 'start_time': 1761131670058, 'channelId': 'CH1', 'exp_duration': 20342}\n"
     ]
    }
   ],
   "source": [
    "dfs_list = []\n",
    "\n",
    "dirs = [f for f in os.listdir(input_directory) if os.path.isdir(os.path.join(input_directory, f))]\n",
    "\n",
    "for directory in dirs:\n",
    "    for input_file in os.listdir(input_directory+'/'+directory):\n",
    "        file_path = input_directory+'/'+directory+'/'\n",
    "        file_name = os.path.basename(input_file)\n",
    "        save_lines = False\n",
    "        if file_name.endswith('.csv'):\n",
    "            with open(file_path+file_name) as f:\n",
    "                for line in f:\n",
    "                # Do something with 'line'        \n",
    "                #line = msg_line\n",
    "                    \n",
    "                    row =  parse_csv_line(line)\n",
    "                    if row[2] == 'MESSAGE': \n",
    "                        row_dict = json.loads(row[3])\n",
    "                        if is_json(row_dict['message']):\n",
    "                            message = json.load(row_dict['message'])\n",
    "                        else:\n",
    "                            message_list = row_dict['message'].split(',')\n",
    "                            message = {}\n",
    "                            # sh post_to_sigless.sh 192.168.50.101:8000 CH1 \"stop,<computerID>,<class>\"\n",
    "                            message['action'] = message_list[0]\n",
    "                            message['computerID'] = message_list[1]\n",
    "                            message['class'] = message_list[2]\n",
    "                            \n",
    "                        print(message)\n",
    "                        \n",
    "                        if message['action'] =='start':\n",
    "                            start_time = row_dict['timestamp']\n",
    "                            message_values = list(message.values())+[str(start_time)]\n",
    "                            file_addition = '_'.join(message_values[1:])\n",
    "                            #print(file_addition)\n",
    "                            outputfile = output_directory+file_addition+'_'+file_name\n",
    "                            # Add information from message\n",
    "                            message.pop('action')\n",
    "                            start_row = message\n",
    "                            start_row['start_time'] = start_time\n",
    "                            start_row['channelId'] =  row_dict['channelId']\n",
    "                            \n",
    "                            if(not(save_lines)):\n",
    "                                f_out = open(outputfile, \"w\")   # 'r' for reading and 'w' for writing                       \n",
    "                                save_lines = True\n",
    "                            else:\n",
    "                                print(outputfile)\n",
    "                                f_out = open(outputfile, \"w\")\n",
    "            \n",
    "                        elif message['action'] == 'stop':\n",
    "                            end_time = row_dict['timestamp']\n",
    "                            duration = end_time - start_time\n",
    "                            start_row['exp_duration'] = duration\n",
    "                            print('meta_row=',start_row)\n",
    "                            save_lines = False # No more lines for this flow  \n",
    "                            f_out.close()   # Close output file\n",
    "                            # save the meta data as the first two lines of the chunked CSV file\n",
    "                            a = list(start_row.keys())\n",
    "                            line1 = ','.join(a) \n",
    "                            a = list(start_row.values())\n",
    "                            line2 = ','.join([str(s) for s in a])\n",
    "                            with open(outputfile, 'r') as original:\n",
    "                                data = original.read()\n",
    "                            with open(outputfile, 'w') as modified:\n",
    "                                modified.write(line1+\"\\n\"+line2+\"\\n\" + data)\n",
    "                            \n",
    "                                \n",
    "                    elif row[2] == 'POWER' and save_lines:  \n",
    "                        f_out.write(line)   # Write line into the file \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05779d-6d89-4366-b276-a51e9310b158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a839a35-a1cc-47d6-8682-b6b1c3fc2c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e7f3d-2f33-42f8-9ceb-30695610052c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
